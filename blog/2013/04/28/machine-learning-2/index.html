<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Arming" />
    <title>2 Linear Regression with Multiple Variables</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Arming" type="application/atom+xml" />
    <link rel="stylesheet" href="/media/css/style.css" />
    <link rel="stylesheet" href="/media/css/highlight.css" />
    <script type="text/javascript" src="/media/js/jquery-1.7.1.min.js"></script>
    <!-- mathjax -->
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script>
         MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'" 
                }
            },
            showProcessingMessages: false
        });
    </script> 
  </head>
  <body>
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>2 Linear Regression with Multiple Variables</h1>
        </header>
        <nav>
        <span><a title="网站首页" class="" href="/">首页</a></span>
        <span><a title="文章分类" class="" href="/categories/">分类</a></span>
        <span><a title="标签索引" class="" href="/tags/">标签</a></span>
        <!--<span><a title="友情链接" class="" href="/links/">链接</a></span>-->
        <span><a title="留言交流" class="" href="/guestbook/">留言</a></span>
        <span><a title="关于站长" class="" href="/about/">关于</a></span>
        <span><a title="种子订阅" class="" href="/feed/" target="_blank">订阅</a></span>
        </nav>
        <article class="content">
        <section class="meta">
<span class="time">
  <time datetime="2013-04-28">2013-04-28</time>
</span>

 | 
<span class="categories">
  分类
  
  <a href="/categories/#course" title="course">course</a>&nbsp;
  
</span>


 | 
<span class="tags">
  标签
  
  <a href="/tags/#ml" title="ml">ml</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="multivariate-linear-regression">Multivariate linear regression</h2>

<h3 id="notation">Notation:</h3>

<ul>
  <li>m = number of training examples</li>
  <li>n = number of features</li>
  <li><script type="math/tex"> x^{(i)} </script> = input(features) of <script type="math/tex"> i^{th} </script> training example.</li>
  <li><script type="math/tex"> x_{j}^{(i)} </script> = value of feature <script type="math/tex"> j </script> in <script type="math/tex"> i^{th} </script> training example.</li>
</ul>

<p><strong>Hypothesis</strong>: <script type="math/tex"> h_{\theta}(x)=\theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \cdots  + \theta_{n}x_{n} </script></p>

<p>For convenience of notation, define <script type="math/tex"> x_{0}=1 </script>.</p>

<script type="math/tex; mode=display"> x=\begin{bmatrix}
x_{0} \\ 
x_{1} \\ 
x_{2} \\ 
\vdots\\ 
x_{n}
\end{bmatrix} \in \mathbb{R}^{n+1}
\ 
\Theta=\begin{bmatrix}
\Theta_{0} \\ 
\Theta_{1} \\ 
\Theta_{2} \\ 
\vdots\\ 
\Theta_{n}
\end{bmatrix} \in \mathbb{R}^{n+1} 
\\
h_{\theta}(x)= \Theta_{0}x_{0} + \Theta_{1}x_{1} + \cdots + \Theta_{n}x_{n}
             = \Theta^{T}x
</script>

<p>Cost funciton:
<script type="math/tex"> J(\theta_{0},\theta_{1},\ldots,\theta_{n})=\frac{1}{2m}\sum_{i=1}^{m} \left ( h_\theta(x^{(i)})-y^{(i)} \right)^2 </script></p>

<p><strong>Gradient descent:</strong></p>

<p>Repeat {
<script type="math/tex"> \theta_{j} := \theta_{j} - \alpha \frac{\partial}{\partial\theta_{j}}J(\theta_{0},\cdots,\theta_{n}) </script>
} (simultaneously update for every <script type="math/tex"> j=0, \cdots, n </script>)</p>

<p>New algorithm <script type="math/tex"> (n \geq 1) </script> :</p>

<p>Repeat {</p>

<p><script type="math/tex"> \theta_{j} := \theta_{j} - \alpha \frac{1}{m}\sum_{i=1}^{m} \left( h_{\theta}(x^{(i)})-y^{(i)} \right) x^{(i)}_{j} </script> }
(simultaneously update <script type="math/tex"> \theta_{j} </script> for <script type="math/tex"> j=0, \cdots, n </script>)</p>

<h3 id="gradient-descent-in-practice-1----feature-scaling">Gradient Descent in Practice 1 – Feature Scaling</h3>

<h4 id="feature-scaling">Feature Scaling</h4>
<p>Get every feature into approximately a <script type="math/tex"> -1 \le x_i \le 1 </script> range.</p>

<h4 id="mean-normalization">Mean normalization</h4>
<p>Replace <script type="math/tex"> x_i </script> with <script type="math/tex"> x_i - \mu_i </script> to make features have aproximately zero mean(Do not apply to  <script type="math/tex"> x_0 = 1 </script>)</p>

<p><script type="math/tex"> x_1 \leftarrow \frac{x_1 - \mu_1}{s_1} </script>, <script type="math/tex"> \mu_1 </script> is the average value of <script type="math/tex"> x_1 </script> in training set(all the value of feature <script type="math/tex"> x_1 or x_i </script>), <script type="math/tex"> s_1 </script> is the range (max-min) (or standard deviation)(max and min is the two values in feature <script type="math/tex"> x_1 or x_i</script>)</p>

<h3 id="gradient-descent-in-practice-2---learning-rate">Gradient Descent in Practice 2 - Learning Rate</h3>

<h4 id="gradient-descent">Gradient descent</h4>
<p><script type="math/tex"> \theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta) </script></p>

<ol>
  <li>“Debugging”: how to make sure gradient descent is working correctly</li>
  <li>How to choose learning rate <script type="math/tex"> \alpha </script>.</li>
</ol>

<p>Making sure gradient descent is working correctly</p>

<ul>
  <li>For sufficiently small <script type="math/tex"> \alpha, J(\theta) </script> should decrease on every iteration</li>
  <li>Buf if <script type="math/tex"> \alpha </script> is too small, gradient descent can be slow to converge.</li>
</ul>

<p><strong>Summary</strong></p>

<ul>
  <li>if <script type="math/tex"> \alpha </script> is too small: slow convergence.</li>
  <li>if <script type="math/tex"> \alpha </script> is too large: <script type="math/tex"> J(\theta) </script> may not decrease on every iteration;may not converge.</li>
</ul>

<p>To choose <script type="math/tex"> \alpha </script>, try <script type="math/tex"> \ldots, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, \ldots </script> </p>

<h3 id="features-and-polynomial-regression">Features and Polynomial（多项式的） Regression</h3>

<h4 id="polynomial-regression">Polynomial Regression</h4>

<script type="math/tex; mode=display"> h_\theta(x)=\theta_0 + \theta_1(size) + \theta_2(size)^2 \\
   h_\theta(x)=\theta_0 + \theta_1(size) + \theta_2\sqrt{(size)} </script>

<h3 id="normal-equation">Normal Equation</h3>
<p>Normal Equation: Method to solve for <script type="math/tex"> \theta </script> analytically.</p>

<script type="math/tex; mode=display"> \theta \in \mathbb{R}^{n+1} \  
J(\theta_{0},\theta_{1},\ldots,\theta_{n})=\frac{1}{2m}\sum_{i=1}^{m} \left ( h_\theta(x^{(i)})-y^{(i)} \right)^2 </script>

<script type="math/tex; mode=display"> \frac{\partial}{\partial\theta_j}J(\theta) = \ldots = 0 \textbf{for every } j \\
\textbf{Solve for } \theta_0, \theta_1, \ldots, \theta_n
</script>

<script type="math/tex; mode=display"> \theta = \left( X^TX \right)^{-1}X^Ty </script>

<script type="math/tex; mode=display">% <![CDATA[
 
m \textbf{ examples }  \left( x^{(1)}, y^{(1)} \right),\ldots, \left( x^{(m)}, y^{(m)} \right) \textbf{;} n \textbf{ features.}
\\
x^{(i)} = \begin{bmatrix} 
x_0^{(i)} \\
x_1^{(i)} \\
x_2^{(i)} \\
\vdots \\
x_n^{(i)} 
\end{bmatrix} \in \mathbb{R}^{n+1} \hspace{15 mm}
\underset{design \ matrix}{\operatorname{X}} = \begin{bmatrix}
\cdots & \left( x^{(1)}\right )^T & \cdots \\
\cdots & \left( x^{(2)}\right )^T & \cdots \\
\vdots & \vdots & \vdots \\
\cdots & \left( x^{(n)}\right )^T & \cdots \\
\end{bmatrix}
\\
X=\begin{bmatrix} 
1 & x_1^{(1)} \\
1 & x_2^{(1)} \\
1 & x_3^{(1)} \\
\vdots & \vdots \\
1 & x_m^{(1)} \\
\end{bmatrix} \hspace{20 mm} 
y= \begin{bmatrix}
y^{(1)}\\
y^{(2)}\\
y^{(3)}\\
\vdots \\
y^{(m)}\\
\end{bmatrix}
 %]]></script>

<p><strong>summary</strong></p>

<p>m training examples, n features.</p>

<p>Gradient Descent:</p>

<ul>
  <li>Need to choose <script type="math/tex"> \alpha </script></li>
  <li>Needs many iterations.</li>
  <li>Works weel even when n is large.</li>
</ul>

<p>Normal Equation:</p>

<ul>
  <li>No need to choose <script type="math/tex"> \alpha </script></li>
  <li>Don’t need to iterate.</li>
  <li>Need to compute <script type="math/tex"> \left( X^TX \right)^{-1} </script></li>
  <li>Slow if n is very large</li>
</ul>

<p>when <script type="math/tex"> n = 10^6 </script>, we should use gradient descent, and when n is smaller than that, we can use normal equation.</p>

<h3 id="normal-equation-noninvertibility">Normal Equation Noninvertibility</h3>
<p>What if <script type="math/tex"> X^TX </script> is non-invertible?</p>

<ul>
  <li>Redundant features(linearly dependent)</li>
  <li>Too many features(e.g. <script type="math/tex"> m \leq n </script>) -
 Delete some features, or use regularization.</li>
</ul>


</section>
<section align="right">
<br/>
<span>
	<a  href="/blog/2013/04/23/machine-learning-1/" class="pageNav"  >上一篇</a>
	&nbsp;&nbsp;&nbsp;
	<a  href="/blog/2013/05/02/libc-function-code/" class="pageNav"  >下一篇</a>
</span>
</section>

	
	<div class="ds-thread" />
		
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"mrmign"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>


        </article>
      </div>

    <footer>
        <p><small>
Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> @ GitHub
             | <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/cn/" target="_blank" title="许可协议">©</a> 2012 - 2015 <a href="/about/">Arming</a>


             | <script src="http://s85.cnzz.com/stat.php?id=1000366411"></script>

         </small></p>
    </footer>

    </div>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-49976813-1', 'mrmign.github.io');
      ga('send', 'pageview');

    </script>
  </body>
</html>
