<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Arming" />
    <title>1 Linear Regression with One Variable</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <link href="/feed/" rel="alternate" title="Arming" type="application/atom+xml" />
    <link rel="stylesheet" href="/media/css/style.css" />
    <link rel="stylesheet" href="/media/css/highlight.css" />
    <script type="text/javascript" src="/media/js/jquery-1.7.1.min.js"></script>
    <!-- mathjax -->
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script>
         MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'" 
                }
            },
            showProcessingMessages: false
        });
    </script> 
  </head>
  <body>
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>1 Linear Regression with One Variable</h1>
        </header>
        <nav>
        <span><a title="网站首页" class="" href="/">首页</a></span>
        <span><a title="文章分类" class="" href="/categories/">分类</a></span>
        <span><a title="标签索引" class="" href="/tags/">标签</a></span>
        <!--<span><a title="友情链接" class="" href="/links/">链接</a></span>-->
        <span><a title="留言交流" class="" href="/guestbook/">留言</a></span>
        <span><a title="关于站长" class="" href="/about/">关于</a></span>
        <span><a title="种子订阅" class="" href="/feed/" target="_blank">订阅</a></span>
        </nav>
        <article class="content">
        <section class="meta">
<span class="time">
  <time datetime="2013-04-23">2013-04-23</time>
</span>

 | 
<span class="categories">
  分类
  
  <a href="/categories/#course" title="course">course</a>&nbsp;
  
</span>


 | 
<span class="tags">
  标签
  
  <a href="/tags/#ml" title="ml">ml</a>&nbsp;
  
</span>

</section>
<section class="post">
<h2 id="machine-learning-algorithms">Machine learning algorithms:</h2>
<ol>
  <li>Supervised learning</li>
  <li>Unsupervised learning</li>
  <li>others:
    <ul>
      <li>Reinforcement learning</li>
      <li>Recommender systems</li>
    </ul>
  </li>
</ol>

<blockquote>
  <p><strong>Practical advice for applying learning algorithms</strong></p>
</blockquote>

<p><strong>Supervised learning</strong> is the machine learning task of inferring a function from labeled training data. The training data consist of a set of training examples.</p>

<p>supervised learning give the “right answer” for each example in the data.</p>

<ul>
  <li>Regression Problem: predict real-valued output(continuous-value)</li>
  <li>Classification Problem: discrete-valued output</li>
</ul>

<h4 id="notation">Notation:</h4>
<ul>
  <li>m = Number of training examles</li>
  <li>x’s = “input” variable / features</li>
  <li>y’s = “output” variable /”target” variable</li>
  <li>(x, y) – one training example</li>
  <li>(x^i, y^i) – i^th training example</li>
</ul>

<p>With the training set and learning algorithm, we get hypothesis, which we use to make predictions, is this linear function.</p>

<p><strong>Hypothesis:</strong> h<sub>θ</sub>(x) = θ<sub>0</sub> + θ<sub>1</sub>x</p>

<script type="math/tex; mode=display">J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^{2}</script>

<p>minimize θ<sub>0</sub>, θ<sub>1</sub>, J(θ<sub>0</sub>, θ<sub>1</sub>) is cost function(squared error function).</p>

<p><strong>Want</strong> <script type="math/tex">\underset{\theta_{0},\theta_{1}}{min} J(\theta_{0},\theta_{1})</script></p>

<p><strong>Gradient descent</strong> to minimize some arbitrary function J.</p>

<h4 id="outline">Outline</h4>
<ul>
  <li>Start with some θ<sub>0</sub>,θ<sub>1</sub></li>
  <li>Keep changing θ<sub>0</sub>,θ<sub>1</sub> to reduce J(θ<sub>0</sub>,θ<sub>1</sub>) until we hopefully end up at a minimum</li>
</ul>

<h4 id="gradient-descent-algorithm">Gradient descent algorithm(梯度下降)</h4>

<script type="math/tex; mode=display">repeat\ until \ convergence 
\left \{  \theta_j := \theta_j - \alpha\frac{\partial }{\partial \theta_j} J(\theta_0, \theta_1)\ \ (for\ j = 0\ and\ j = 1) \right \}</script>

<p>Here α is learning rate,it controls how big a step we take when updating parameter theta J.<script type="math/tex">\frac{\partial}{\partial\theta_{i}}J(\theta_{0},\theta_{1})</script> is the derivative(导数) term.</p>

<p>We must update θ<sub>0</sub> and θ<sub>1</sub> simultaneously.</p>

<p>Correct: Simultaneously update</p>

<script type="math/tex; mode=display">temp0 := \theta_0 - \alpha \frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1)\\
temp1 := \theta_1 - \alpha \frac{\partial }{\partial \theta_1} J(\theta_0, \theta_1)\\
\theta_0 := temp0 \\
\theta_1 := temp1</script>

<p><strong>!Incorrect</strong></p>

<script type="math/tex; mode=display">temp0 := \theta_0 - \alpha \frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1)\\
\theta_0 := temp0 \\
temp1 := \theta_1 - \alpha \frac{\partial }{\partial \theta_1} J(\theta_0, \theta_1)\\
\theta_1 := temp1</script>

<h4 id="gradient-descent-alogirthm">Gradient descent alogirthm</h4>
<p>repeat until convergence {</p>

<script type="math/tex; mode=display">\theta_{0}:=\theta_{0}-\frac{1}{m}\sum^{m}_{i=1}(h_{\theta}(x^{(i)})-y^{(i)})</script>

<script type="math/tex; mode=display">\theta_{1}:=\theta_{1}-\frac{1}{m}\sum^{m}_{i=1}(h_{\theta}(x^{(i)})-y^{(i)})\cdot x^{(i)}</script>

<p>}</p>

<p><strong>Unsupervised learning</strong> refers to the problem of trying to find hidden structure in unlabeled data.</p>


</section>
<section align="right">
<br/>
<span>
	<a  href="/2013/04/22/programming-pearls/" class="pageNav"  >上一篇</a>
	&nbsp;&nbsp;&nbsp;
	<a  href="/2013/04/28/machine-learning-2/" class="pageNav"  >下一篇</a>
</span>
</section>

	
	<div class="ds-thread" />
		
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"mrmign"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>


        </article>
      </div>

    <footer>
        <p><small>
Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> @ GitHub
             | <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/cn/" target="_blank" title="许可协议">©</a> 2012 - 2015 <a href="/about/">Arming</a>


             | <script src="http://s85.cnzz.com/stat.php?id=1000366411"></script>

         </small></p>
    </footer>

    </div>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-49976813-1', 'mrmign.github.io');
      ga('send', 'pageview');

    </script>
  </body>
</html>
